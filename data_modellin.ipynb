{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "46f076f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>booking_datetime</th>\n",
       "      <th>booking_hour</th>\n",
       "      <th>Booking ID</th>\n",
       "      <th>Booking Status</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Vehicle Type</th>\n",
       "      <th>Pickup Location</th>\n",
       "      <th>Drop Location</th>\n",
       "      <th>...</th>\n",
       "      <th>wind_speed_10m_dropoff_scaled.1</th>\n",
       "      <th>precipitation_log_scaled</th>\n",
       "      <th>precipitation_log_scaled.1</th>\n",
       "      <th>rain_log_scaled</th>\n",
       "      <th>rain_log_scaled.1</th>\n",
       "      <th>snowfall_log_scaled</th>\n",
       "      <th>snowfall_log_scaled.1</th>\n",
       "      <th>precipitation_dropoff_log_scaled</th>\n",
       "      <th>rain_dropoff_log_scaled</th>\n",
       "      <th>snowfall_dropoff_log_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-23</td>\n",
       "      <td>12:29:38</td>\n",
       "      <td>2024-03-23 12:29:38</td>\n",
       "      <td>2024-03-23 12:00:00</td>\n",
       "      <td>\"CNR5884300\"</td>\n",
       "      <td>No Driver Found</td>\n",
       "      <td>\"CID1982111\"</td>\n",
       "      <td>eBike</td>\n",
       "      <td>Palam Vihar</td>\n",
       "      <td>Jhilmil</td>\n",
       "      <td>...</td>\n",
       "      <td>1.392857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-11-29</td>\n",
       "      <td>18:01:39</td>\n",
       "      <td>2024-11-29 18:01:39</td>\n",
       "      <td>2024-11-29 18:00:00</td>\n",
       "      <td>\"CNR1326809\"</td>\n",
       "      <td>Incomplete</td>\n",
       "      <td>\"CID4604802\"</td>\n",
       "      <td>Go Sedan</td>\n",
       "      <td>Shastri Nagar</td>\n",
       "      <td>Gurgaon Sector 56</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-08-23</td>\n",
       "      <td>08:56:10</td>\n",
       "      <td>2024-08-23 08:56:10</td>\n",
       "      <td>2024-08-23 08:00:00</td>\n",
       "      <td>\"CNR8494506\"</td>\n",
       "      <td>Completed</td>\n",
       "      <td>\"CID9202816\"</td>\n",
       "      <td>Auto</td>\n",
       "      <td>Khandsa</td>\n",
       "      <td>Malviya Nagar</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.464286</td>\n",
       "      <td>0.182322</td>\n",
       "      <td>0.182322</td>\n",
       "      <td>0.182322</td>\n",
       "      <td>0.182322</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-10-21</td>\n",
       "      <td>17:17:25</td>\n",
       "      <td>2024-10-21 17:17:25</td>\n",
       "      <td>2024-10-21 17:00:00</td>\n",
       "      <td>\"CNR8906825\"</td>\n",
       "      <td>Completed</td>\n",
       "      <td>\"CID2610914\"</td>\n",
       "      <td>Premier Sedan</td>\n",
       "      <td>Central Secretariat</td>\n",
       "      <td>Inderlok</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.214286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-09-16</td>\n",
       "      <td>22:08:00</td>\n",
       "      <td>2024-09-16 22:08:00</td>\n",
       "      <td>2024-09-16 22:00:00</td>\n",
       "      <td>\"CNR1950162\"</td>\n",
       "      <td>Completed</td>\n",
       "      <td>\"CID9933542\"</td>\n",
       "      <td>Bike</td>\n",
       "      <td>Ghitorni Village</td>\n",
       "      <td>Khan Market</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Time     booking_datetime         booking_hour  \\\n",
       "0  2024-03-23  12:29:38  2024-03-23 12:29:38  2024-03-23 12:00:00   \n",
       "1  2024-11-29  18:01:39  2024-11-29 18:01:39  2024-11-29 18:00:00   \n",
       "2  2024-08-23  08:56:10  2024-08-23 08:56:10  2024-08-23 08:00:00   \n",
       "3  2024-10-21  17:17:25  2024-10-21 17:17:25  2024-10-21 17:00:00   \n",
       "4  2024-09-16  22:08:00  2024-09-16 22:08:00  2024-09-16 22:00:00   \n",
       "\n",
       "     Booking ID   Booking Status   Customer ID   Vehicle Type  \\\n",
       "0  \"CNR5884300\"  No Driver Found  \"CID1982111\"          eBike   \n",
       "1  \"CNR1326809\"       Incomplete  \"CID4604802\"       Go Sedan   \n",
       "2  \"CNR8494506\"        Completed  \"CID9202816\"           Auto   \n",
       "3  \"CNR8906825\"        Completed  \"CID2610914\"  Premier Sedan   \n",
       "4  \"CNR1950162\"        Completed  \"CID9933542\"           Bike   \n",
       "\n",
       "       Pickup Location      Drop Location  ...  \\\n",
       "0          Palam Vihar            Jhilmil  ...   \n",
       "1        Shastri Nagar  Gurgaon Sector 56  ...   \n",
       "2              Khandsa      Malviya Nagar  ...   \n",
       "3  Central Secretariat           Inderlok  ...   \n",
       "4     Ghitorni Village        Khan Market  ...   \n",
       "\n",
       "   wind_speed_10m_dropoff_scaled.1 precipitation_log_scaled  \\\n",
       "0                         1.392857                 0.000000   \n",
       "1                        -1.250000                 0.000000   \n",
       "2                        -0.464286                 0.182322   \n",
       "3                        -0.214286                 0.000000   \n",
       "4                         0.017857                 0.000000   \n",
       "\n",
       "   precipitation_log_scaled.1 rain_log_scaled  rain_log_scaled.1  \\\n",
       "0                    0.000000        0.000000           0.000000   \n",
       "1                    0.000000        0.000000           0.000000   \n",
       "2                    0.182322        0.182322           0.182322   \n",
       "3                    0.000000        0.000000           0.000000   \n",
       "4                    0.000000        0.000000           0.000000   \n",
       "\n",
       "  snowfall_log_scaled  snowfall_log_scaled.1  \\\n",
       "0                 0.0                    0.0   \n",
       "1                 0.0                    0.0   \n",
       "2                 0.0                    0.0   \n",
       "3                 0.0                    0.0   \n",
       "4                 0.0                    0.0   \n",
       "\n",
       "   precipitation_dropoff_log_scaled  rain_dropoff_log_scaled  \\\n",
       "0                               0.0                      0.0   \n",
       "1                               0.0                      0.0   \n",
       "2                               0.0                      0.0   \n",
       "3                               0.0                      0.0   \n",
       "4                               0.0                      0.0   \n",
       "\n",
       "   snowfall_dropoff_log_scaled  \n",
       "0                          0.0  \n",
       "1                          0.0  \n",
       "2                          0.0  \n",
       "3                          0.0  \n",
       "4                          0.0  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned CSV file\n",
    "df = pd.read_csv(\"ncr_ride_bookings_with_weather_filled_scaled_short.csv\")\n",
    "\n",
    "# Display the first 5 rows to preview the data structure\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4ebc5346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders ready.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Cell 1) Imports & folders\n",
    "# -----------------------------\n",
    "import os\n",
    "import uuid\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    f1_score, precision_score, recall_score, accuracy_score, roc_auc_score\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "# Make sure artifact folders exist\n",
    "Path(\"artifacts/metrics\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"artifacts/plots\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"artifacts/models\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Folders ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5be35a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Cell 2) Feature inference helpers\n",
    "# -----------------------------\n",
    "from typing import Tuple\n",
    "\n",
    "def infer_feature_lists(df: pd.DataFrame, target_col: str) -> Tuple[List[str], List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Infer feature columns based on naming patterns created by preprocessing.\n",
    "    Returns (numeric_scaled, categorical_fill, missing_flags).\n",
    "    \"\"\"\n",
    "    cols = [c for c in df.columns if c != target_col]\n",
    "\n",
    "    numeric_scaled = [c for c in cols if c.endswith(\"_scaled\") or c.endswith(\"_log_scaled\")]\n",
    "    categorical_fill = [c for c in cols if c.endswith(\"_fill\") or c == \"Vehicle Type\"]\n",
    "    missing_flags = [c for c in cols if c.endswith(\"_missing_flag\")]\n",
    "\n",
    "    # De-duplicate while preserving order\n",
    "    used = set()\n",
    "    ordered_groups = []\n",
    "    for group in (numeric_scaled, categorical_fill, missing_flags):\n",
    "        tmp = []\n",
    "        for c in group:\n",
    "            if c not in used:\n",
    "                tmp.append(c)\n",
    "                used.add(c)\n",
    "        ordered_groups.append(tmp)\n",
    "\n",
    "    numeric_scaled, categorical_fill, missing_flags = ordered_groups\n",
    "    print(f\"#numeric_scaled={len(numeric_scaled)}, #categorical_fill={len(categorical_fill)}, #missing_flags={len(missing_flags)}\")\n",
    "    return numeric_scaled, categorical_fill, missing_flags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "09d37779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Cell 3) Build preprocessor\n",
    "# -----------------------------\n",
    "def build_preprocessor(\n",
    "    numeric_scaled: List[str],\n",
    "    categorical_fill: List[str],\n",
    "    missing_flags: List[str]\n",
    ") -> ColumnTransformer:\n",
    "    \"\"\"\n",
    "    One-hot encode categorical; passthrough numeric+flags (already scaled / binary).\n",
    "    \"\"\"\n",
    "    num_and_flags = numeric_scaled + missing_flags\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_fill),\n",
    "            (\"num\", \"passthrough\", num_and_flags),\n",
    "        ],\n",
    "        remainder=\"drop\",\n",
    "    )\n",
    "    return preprocessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8aa15080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Cell 4) Model registry\n",
    "# -----------------------------\n",
    "def get_models(random_state: int = 42) -> Dict[str, object]:\n",
    "    \"\"\"\n",
    "    Baselines for logistic regression, decision tree, and ensembles.\n",
    "    \"\"\"\n",
    "    models = {\n",
    "        \"logreg_l2\": LogisticRegression(\n",
    "            max_iter=1000,\n",
    "            class_weight=\"balanced\",\n",
    "            random_state=random_state\n",
    "        ),\n",
    "        \"dtree\": DecisionTreeClassifier(\n",
    "            max_depth=None,\n",
    "            min_samples_split=5,\n",
    "            class_weight=\"balanced\",\n",
    "            random_state=random_state\n",
    "        ),\n",
    "        \"rf_300\": RandomForestClassifier(\n",
    "            n_estimators=300,\n",
    "            max_depth=None,\n",
    "            n_jobs=-1,\n",
    "            class_weight=\"balanced\",\n",
    "            random_state=random_state\n",
    "        ),\n",
    "        \"gbdt\": GradientBoostingClassifier(\n",
    "            random_state=random_state\n",
    "        ),\n",
    "    }\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8a1cfe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Cell 5) Exact-label mapping & safer CV\n",
    "# -----------------------------\n",
    "from typing import Optional, Iterable\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def map_status_to_binary_exact_labels(s: str, positive_label_set: Iterable[str]) -> int:\n",
    "    \"\"\"\n",
    "    Map Booking Status to binary using an explicit label set.\n",
    "    Returns 1 if the normalized label is in positive_label_set, else 0.\n",
    "    \"\"\"\n",
    "    if pd.isna(s):\n",
    "        return 0\n",
    "    s_norm = str(s).strip()\n",
    "    return int(s_norm in set(positive_label_set))\n",
    "\n",
    "def safe_stratified_cv(y_bin: pd.Series, n_splits: int = 5, random_state: int = 42):\n",
    "    \"\"\"\n",
    "    Yield StratifiedKFold splits ensuring at least 2 classes per fold.\n",
    "    Reduce n_splits if the minority class is too small; skip degenerate folds.\n",
    "    \"\"\"\n",
    "    vc = y_bin.value_counts()\n",
    "    if vc.nunique() == 1:\n",
    "        raise ValueError(\n",
    "            \"Only one class present overall after mapping. Adjust your positive_label_set or labels.\"\n",
    "        )\n",
    "    minority = vc.min()\n",
    "    n_splits = min(n_splits, minority)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    for fold_id, (tr_idx, va_idx) in enumerate(skf.split(np.zeros(len(y_bin)), y_bin), 1):\n",
    "        y_tr, y_va = y_bin.iloc[tr_idx], y_bin.iloc[va_idx]\n",
    "        if y_tr.nunique() < 2 or y_va.nunique() < 2:\n",
    "            print(f\"⚠️ Skipping fold {fold_id}: single class in train/valid.\")\n",
    "            continue\n",
    "        yield fold_id, tr_idx, va_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9de5b977",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ']' (1946838344.py, line 38)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[45], line 38\u001b[1;36m\u001b[0m\n\u001b[1;33m    X_tr, X_va = X.iloc[tr_idx], X_]()\u001b[0m\n\u001b[1;37m                                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unmatched ']'\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Cell 6) Evaluate models with CV (exact label set)\n",
    "# -----------------------------\n",
    "def evaluate_models_cv(\n",
    "    df: pd.DataFrame,\n",
    "    target_col: str,\n",
    "    positive_label_set: Iterable[str],\n",
    "    n_splits: int = 5,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build preprocessor, train multiple models with StratifiedKFold CV,\n",
    "    and return a tidy metrics dataframe:\n",
    "      ['run_id','timestamp','model_name','fold','metric','value','params']\n",
    "    \"\"\"\n",
    "    # 1) Normalize target text and map to binary via exact label set\n",
    "    y_text = df[target_col].astype(str).str.strip()\n",
    "    y_bin = y_text.apply(lambda s: map_status_to_binary_exact_labels(s, positive_label_set)).astype(int)\n",
    "    print(\"Label distribution:\", y_bin.value_counts().to_dict())\n",
    "    if y_bin.value_counts().min() < 2:\n",
    "        raise ValueError(\"Not enough minority samples. Adjust positive_label_set or filter data.\")\n",
    "\n",
    "    # 2) Infer features & build X\n",
    "    numeric_scaled, categorical_fill, missing_flags = infer_feature_lists(df, target_col)\n",
    "    X = df[numeric_scaled + categorical_fill + missing_flags].copy()\n",
    "\n",
    "    # 3) Preprocessor & models\n",
    "    pre = build_preprocessor(numeric_scaled, categorical_fill, missing_flags)\n",
    "    models = get_models()\n",
    "\n",
    "    # 4) CV loop\n",
    "    rows = []\n",
    "    run_id = str(uuid.uuid4())\n",
    "    ts = int(time.time())\n",
    "\n",
    "    for model_name, base_model in models.items():\n",
    "        pipe = Pipeline(steps=[(\"preprocess\", pre), (\"model\", base_model)])\n",
    "        for fold_id, tr_idx, va_idx in safe_stratified_cv(y_bin, n_splits=n_splits):\n",
    "            X_tr, X_va = X.iloc[tr_idx], X_]()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09aa6f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146614, 68)\n",
      "Index(['Date', 'Time', 'booking_datetime', 'booking_hour', 'Booking ID',\n",
      "       'Booking Status', 'Customer ID', 'Vehicle Type', 'Pickup Location',\n",
      "       'Drop Location'],\n",
      "      dtype='object')\n",
      "#numeric_scaled=20, #categorical_fill=9, #missing_flags=3\n",
      "Label distribution: {0: 101146, 1: 45468}\n",
      "Saved metrics to artifacts/metrics/metrics.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dtree</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gbdt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logreg_l2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rf_300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_name  mean  std\n",
       "0      dtree   1.0  0.0\n",
       "1       gbdt   1.0  0.0\n",
       "2  logreg_l2   1.0  0.0\n",
       "3     rf_300   1.0  0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Cell 7) Run: load data, set positive labels, evaluate, save, leaderboard\n",
    "# -----------------------------\n",
    "# 7.1 Load cleaned CSV from teammate\n",
    "csv_path = \"ncr_ride_bookings_with_weather_filled_scaled_short.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# (optional) quick peek\n",
    "print(df.shape)\n",
    "print(df.columns[:10])\n",
    "\n",
    "# 7.2 Choose target & define exact positive label set based on your dataset\n",
    "target_col = \"Booking Status\"\n",
    "\n",
    "# From your screenshot / dataset (adjust if you find more):\n",
    "# { \"Cancelled by Customer\", \"Cancelled by Driver\", \"Completed\", \"Incomplete\", \"No Driver Found\" }\n",
    "POSITIVE_LABELS = {\n",
    "    \"Cancelled by Customer\",\n",
    "    \"Cancelled by Driver\",\n",
    "    \"Incomplete\",\n",
    "    \"No Driver Found\"\n",
    "}\n",
    "NEGATIVE_LABELS = {\"Completed\"}  # optional for sanity check\n",
    "\n",
    "# Sanity: list unknown labels not covered by the sets\n",
    "df[target_col] = df[target_col].astype(str).str.strip()\n",
    "known = POSITIVE_LABELS | NEGATIVE_LABELS\n",
    "unknown = sorted(set(df[target_col].unique()) - known)\n",
    "print(\"Unknown labels (not in POSITIVE or NEGATIVE sets):\", unknown)\n",
    "\n",
    "# 7.3 Evaluate with CV using the exact label set\n",
    "metrics_df = evaluate_models_cv(\n",
    "    df=df,\n",
    "    target_col=target_col,\n",
    "    positive_label_set=POSITIVE_LABELS,\n",
    "    n_splits=5\n",
    ")\n",
    "\n",
    "# 7.4 Save metrics CSV for visualization teammate\n",
    "from pathlib import Path\n",
    "Path(\"artifacts/metrics\").mkdir(parents=True, exist_ok=True)\n",
    "out_csv = \"artifacts/metrics/metrics.csv\"\n",
    "metrics_df.to_csv(out_csv, index=False)\n",
    "print(f\"Saved metrics to {out_csv}\")\n",
    "\n",
    "# 7.5 Quick leaderboard by F1\n",
    "leaderboard = (\n",
    "    metrics_df[metrics]()_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73d7848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>model_name</th>\n",
       "      <th>fold</th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6142a5b1-cd00-4028-b027-8ddf3db0f934</td>\n",
       "      <td>1758155153</td>\n",
       "      <td>logreg_l2</td>\n",
       "      <td>1</td>\n",
       "      <td>f1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 1.0, 'class_weight': 'balanced', 'dual':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6142a5b1-cd00-4028-b027-8ddf3db0f934</td>\n",
       "      <td>1758155153</td>\n",
       "      <td>logreg_l2</td>\n",
       "      <td>1</td>\n",
       "      <td>precision</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 1.0, 'class_weight': 'balanced', 'dual':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6142a5b1-cd00-4028-b027-8ddf3db0f934</td>\n",
       "      <td>1758155153</td>\n",
       "      <td>logreg_l2</td>\n",
       "      <td>1</td>\n",
       "      <td>recall</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 1.0, 'class_weight': 'balanced', 'dual':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6142a5b1-cd00-4028-b027-8ddf3db0f934</td>\n",
       "      <td>1758155153</td>\n",
       "      <td>logreg_l2</td>\n",
       "      <td>1</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 1.0, 'class_weight': 'balanced', 'dual':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6142a5b1-cd00-4028-b027-8ddf3db0f934</td>\n",
       "      <td>1758155153</td>\n",
       "      <td>logreg_l2</td>\n",
       "      <td>1</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 1.0, 'class_weight': 'balanced', 'dual':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6142a5b1-cd00-4028-b027-8ddf3db0f934</td>\n",
       "      <td>1758155153</td>\n",
       "      <td>logreg_l2</td>\n",
       "      <td>2</td>\n",
       "      <td>f1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 1.0, 'class_weight': 'balanced', 'dual':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6142a5b1-cd00-4028-b027-8ddf3db0f934</td>\n",
       "      <td>1758155153</td>\n",
       "      <td>logreg_l2</td>\n",
       "      <td>2</td>\n",
       "      <td>precision</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 1.0, 'class_weight': 'balanced', 'dual':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6142a5b1-cd00-4028-b027-8ddf3db0f934</td>\n",
       "      <td>1758155153</td>\n",
       "      <td>logreg_l2</td>\n",
       "      <td>2</td>\n",
       "      <td>recall</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 1.0, 'class_weight': 'balanced', 'dual':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6142a5b1-cd00-4028-b027-8ddf3db0f934</td>\n",
       "      <td>1758155153</td>\n",
       "      <td>logreg_l2</td>\n",
       "      <td>2</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 1.0, 'class_weight': 'balanced', 'dual':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6142a5b1-cd00-4028-b027-8ddf3db0f934</td>\n",
       "      <td>1758155153</td>\n",
       "      <td>logreg_l2</td>\n",
       "      <td>2</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 1.0, 'class_weight': 'balanced', 'dual':...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 run_id   timestamp model_name  fold  \\\n",
       "0  6142a5b1-cd00-4028-b027-8ddf3db0f934  1758155153  logreg_l2     1   \n",
       "1  6142a5b1-cd00-4028-b027-8ddf3db0f934  1758155153  logreg_l2     1   \n",
       "2  6142a5b1-cd00-4028-b027-8ddf3db0f934  1758155153  logreg_l2     1   \n",
       "3  6142a5b1-cd00-4028-b027-8ddf3db0f934  1758155153  logreg_l2     1   \n",
       "4  6142a5b1-cd00-4028-b027-8ddf3db0f934  1758155153  logreg_l2     1   \n",
       "5  6142a5b1-cd00-4028-b027-8ddf3db0f934  1758155153  logreg_l2     2   \n",
       "6  6142a5b1-cd00-4028-b027-8ddf3db0f934  1758155153  logreg_l2     2   \n",
       "7  6142a5b1-cd00-4028-b027-8ddf3db0f934  1758155153  logreg_l2     2   \n",
       "8  6142a5b1-cd00-4028-b027-8ddf3db0f934  1758155153  logreg_l2     2   \n",
       "9  6142a5b1-cd00-4028-b027-8ddf3db0f934  1758155153  logreg_l2     2   \n",
       "\n",
       "      metric  value                                             params  \n",
       "0         f1    1.0  {'C': 1.0, 'class_weight': 'balanced', 'dual':...  \n",
       "1  precision    1.0  {'C': 1.0, 'class_weight': 'balanced', 'dual':...  \n",
       "2     recall    1.0  {'C': 1.0, 'class_weight': 'balanced', 'dual':...  \n",
       "3   accuracy    1.0  {'C': 1.0, 'class_weight': 'balanced', 'dual':...  \n",
       "4    roc_auc    1.0  {'C': 1.0, 'class_weight': 'balanced', 'dual':...  \n",
       "5         f1    1.0  {'C': 1.0, 'class_weight': 'balanced', 'dual':...  \n",
       "6  precision    1.0  {'C': 1.0, 'class_weight': 'balanced', 'dual':...  \n",
       "7     recall    1.0  {'C': 1.0, 'class_weight': 'balanced', 'dual':...  \n",
       "8   accuracy    1.0  {'C': 1.0, 'class_weight': 'balanced', 'dual':...  \n",
       "9    roc_auc    1.0  {'C': 1.0, 'class_weight': 'balanced', 'dual':...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# (Optional) Cell 8) Peek metrics\n",
    "# -----------------------------\n",
    "pd.read_csv(\"artifacts/metrics/metrics.csv\").head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57acc3b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Time', 'booking_datetime', 'booking_hour', 'Booking ID',\n",
       "       'Booking Status', 'Customer ID', 'Vehicle Type', 'Pickup Location',\n",
       "       'Drop Location', 'Cancelled Rides by Customer_fill',\n",
       "       'Reason for cancelling by Customer_fill',\n",
       "       'Cancelled Rides by Driver_fill', 'Driver Cancellation Reason_fill',\n",
       "       'Incomplete Rides_fill', 'Incomplete Rides Reason_fill',\n",
       "       'Avg VTAT_fill_scaled', 'VTAT_missing_flag', 'CTAT_missing_flag',\n",
       "       'Avg CTAT_fill_scaled', 'BookingValue_missing_flag',\n",
       "       'Booking Value_fill_scaled', 'Ride Distance_fill_scaled',\n",
       "       'Driver Ratings_fill', 'Customer Rating_fill', 'pick_longitude',\n",
       "       'pick_latitude', 'pick_address', 'pick_region', 'pick_locality',\n",
       "       'drop_longitude', 'drop_latitude', 'drop_address', 'drop_region',\n",
       "       'drop_locality', 'pick_station_latitude', 'pick_station_longitude',\n",
       "       'drop_station_latitude', 'drop_station_longitude',\n",
       "       'temperature_2m_scaled', 'temperature_2m_scaled.1',\n",
       "       'relative_humidity_2m_scaled', 'relative_humidity_2m_scaled.1',\n",
       "       'dew_point_2m_scaled', 'dew_point_2m_scaled.1',\n",
       "       'apparent_temperature_scaled', 'apparent_temperature_scaled.1',\n",
       "       'wind_speed_10m_scaled', 'wind_speed_10m_scaled.1',\n",
       "       'temperature_2m_dropoff_scaled', 'temperature_2m_dropoff_scaled.1',\n",
       "       'relative_humidity_2m_dropoff_scaled',\n",
       "       'relative_humidity_2m_dropoff_scaled.1', 'dew_point_2m_dropoff_scaled',\n",
       "       'dew_point_2m_dropoff_scaled.1', 'apparent_temperature_dropoff_scaled',\n",
       "       'apparent_temperature_dropoff_scaled.1',\n",
       "       'wind_speed_10m_dropoff_scaled', 'wind_speed_10m_dropoff_scaled.1',\n",
       "       'precipitation_log_scaled', 'precipitation_log_scaled.1',\n",
       "       'rain_log_scaled', 'rain_log_scaled.1', 'snowfall_log_scaled',\n",
       "       'snowfall_log_scaled.1', 'precipitation_dropoff_log_scaled',\n",
       "       'rain_dropoff_log_scaled', 'snowfall_dropoff_log_scaled'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad5e9ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
