{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "46f076f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>booking_datetime</th>\n",
       "      <th>booking_hour</th>\n",
       "      <th>Booking ID</th>\n",
       "      <th>Booking Status</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Vehicle Type</th>\n",
       "      <th>Pickup Location</th>\n",
       "      <th>Drop Location</th>\n",
       "      <th>...</th>\n",
       "      <th>wind_speed_10m_dropoff_scaled.1</th>\n",
       "      <th>precipitation_log_scaled</th>\n",
       "      <th>precipitation_log_scaled.1</th>\n",
       "      <th>rain_log_scaled</th>\n",
       "      <th>rain_log_scaled.1</th>\n",
       "      <th>snowfall_log_scaled</th>\n",
       "      <th>snowfall_log_scaled.1</th>\n",
       "      <th>precipitation_dropoff_log_scaled</th>\n",
       "      <th>rain_dropoff_log_scaled</th>\n",
       "      <th>snowfall_dropoff_log_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-23</td>\n",
       "      <td>12:29:38</td>\n",
       "      <td>2024-03-23 12:29:38</td>\n",
       "      <td>2024-03-23 12:00:00</td>\n",
       "      <td>\"CNR5884300\"</td>\n",
       "      <td>No Driver Found</td>\n",
       "      <td>\"CID1982111\"</td>\n",
       "      <td>eBike</td>\n",
       "      <td>Palam Vihar</td>\n",
       "      <td>Jhilmil</td>\n",
       "      <td>...</td>\n",
       "      <td>1.392857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-11-29</td>\n",
       "      <td>18:01:39</td>\n",
       "      <td>2024-11-29 18:01:39</td>\n",
       "      <td>2024-11-29 18:00:00</td>\n",
       "      <td>\"CNR1326809\"</td>\n",
       "      <td>Incomplete</td>\n",
       "      <td>\"CID4604802\"</td>\n",
       "      <td>Go Sedan</td>\n",
       "      <td>Shastri Nagar</td>\n",
       "      <td>Gurgaon Sector 56</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-08-23</td>\n",
       "      <td>08:56:10</td>\n",
       "      <td>2024-08-23 08:56:10</td>\n",
       "      <td>2024-08-23 08:00:00</td>\n",
       "      <td>\"CNR8494506\"</td>\n",
       "      <td>Completed</td>\n",
       "      <td>\"CID9202816\"</td>\n",
       "      <td>Auto</td>\n",
       "      <td>Khandsa</td>\n",
       "      <td>Malviya Nagar</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.464286</td>\n",
       "      <td>0.182322</td>\n",
       "      <td>0.182322</td>\n",
       "      <td>0.182322</td>\n",
       "      <td>0.182322</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-10-21</td>\n",
       "      <td>17:17:25</td>\n",
       "      <td>2024-10-21 17:17:25</td>\n",
       "      <td>2024-10-21 17:00:00</td>\n",
       "      <td>\"CNR8906825\"</td>\n",
       "      <td>Completed</td>\n",
       "      <td>\"CID2610914\"</td>\n",
       "      <td>Premier Sedan</td>\n",
       "      <td>Central Secretariat</td>\n",
       "      <td>Inderlok</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.214286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-09-16</td>\n",
       "      <td>22:08:00</td>\n",
       "      <td>2024-09-16 22:08:00</td>\n",
       "      <td>2024-09-16 22:00:00</td>\n",
       "      <td>\"CNR1950162\"</td>\n",
       "      <td>Completed</td>\n",
       "      <td>\"CID9933542\"</td>\n",
       "      <td>Bike</td>\n",
       "      <td>Ghitorni Village</td>\n",
       "      <td>Khan Market</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Time     booking_datetime         booking_hour  \\\n",
       "0  2024-03-23  12:29:38  2024-03-23 12:29:38  2024-03-23 12:00:00   \n",
       "1  2024-11-29  18:01:39  2024-11-29 18:01:39  2024-11-29 18:00:00   \n",
       "2  2024-08-23  08:56:10  2024-08-23 08:56:10  2024-08-23 08:00:00   \n",
       "3  2024-10-21  17:17:25  2024-10-21 17:17:25  2024-10-21 17:00:00   \n",
       "4  2024-09-16  22:08:00  2024-09-16 22:08:00  2024-09-16 22:00:00   \n",
       "\n",
       "     Booking ID   Booking Status   Customer ID   Vehicle Type  \\\n",
       "0  \"CNR5884300\"  No Driver Found  \"CID1982111\"          eBike   \n",
       "1  \"CNR1326809\"       Incomplete  \"CID4604802\"       Go Sedan   \n",
       "2  \"CNR8494506\"        Completed  \"CID9202816\"           Auto   \n",
       "3  \"CNR8906825\"        Completed  \"CID2610914\"  Premier Sedan   \n",
       "4  \"CNR1950162\"        Completed  \"CID9933542\"           Bike   \n",
       "\n",
       "       Pickup Location      Drop Location  ...  \\\n",
       "0          Palam Vihar            Jhilmil  ...   \n",
       "1        Shastri Nagar  Gurgaon Sector 56  ...   \n",
       "2              Khandsa      Malviya Nagar  ...   \n",
       "3  Central Secretariat           Inderlok  ...   \n",
       "4     Ghitorni Village        Khan Market  ...   \n",
       "\n",
       "   wind_speed_10m_dropoff_scaled.1 precipitation_log_scaled  \\\n",
       "0                         1.392857                 0.000000   \n",
       "1                        -1.250000                 0.000000   \n",
       "2                        -0.464286                 0.182322   \n",
       "3                        -0.214286                 0.000000   \n",
       "4                         0.017857                 0.000000   \n",
       "\n",
       "   precipitation_log_scaled.1 rain_log_scaled  rain_log_scaled.1  \\\n",
       "0                    0.000000        0.000000           0.000000   \n",
       "1                    0.000000        0.000000           0.000000   \n",
       "2                    0.182322        0.182322           0.182322   \n",
       "3                    0.000000        0.000000           0.000000   \n",
       "4                    0.000000        0.000000           0.000000   \n",
       "\n",
       "  snowfall_log_scaled  snowfall_log_scaled.1  \\\n",
       "0                 0.0                    0.0   \n",
       "1                 0.0                    0.0   \n",
       "2                 0.0                    0.0   \n",
       "3                 0.0                    0.0   \n",
       "4                 0.0                    0.0   \n",
       "\n",
       "   precipitation_dropoff_log_scaled  rain_dropoff_log_scaled  \\\n",
       "0                               0.0                      0.0   \n",
       "1                               0.0                      0.0   \n",
       "2                               0.0                      0.0   \n",
       "3                               0.0                      0.0   \n",
       "4                               0.0                      0.0   \n",
       "\n",
       "   snowfall_dropoff_log_scaled  \n",
       "0                          0.0  \n",
       "1                          0.0  \n",
       "2                          0.0  \n",
       "3                          0.0  \n",
       "4                          0.0  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned CSV file\n",
    "df = pd.read_csv(\"ncr_ride_bookings_with_weather_filled_scaled_short.csv\")\n",
    "\n",
    "# Display the first 5 rows to preview the data structure\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4ebc5346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders ready.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Cell 1) Imports & folders\n",
    "# -----------------------------\n",
    "import os\n",
    "import uuid\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    f1_score, precision_score, recall_score, accuracy_score, roc_auc_score\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "# Make sure artifact folders exist\n",
    "Path(\"artifacts/metrics\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"artifacts/plots\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"artifacts/models\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Folders ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be35a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Cell 2) Feature inference (with whitelist and de-dup)\n",
    "# -----------------------------\n",
    "from typing import List, Tuple\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Deduplicate duplicate column names (keep first occurrence)\n",
    "before = len(df.columns)\n",
    "df = df.loc[:, ~df.columns.duplicated(keep=\"first\")]\n",
    "after = len(df.columns)\n",
    "print(f\"Deduplicated columns: {before} -> {after}\")\n",
    "\n",
    "# 2) Raw numeric features WITHOUT suffixes that we still want to include\n",
    "NUMERIC_RAW_WHITELIST = [\n",
    "    \"booking_hour\",\n",
    "    \"pick_longitude\", \"pick_latitude\",\n",
    "    \"drop_longitude\", \"drop_latitude\",\n",
    "    \"pick_station_latitude\", \"pick_station_longitude\",\n",
    "    \"drop_station_latitude\", \"drop_station_longitude\",\n",
    "]\n",
    "\n",
    "# 3) Always-exclude list (IDs, free-text addresses)\n",
    "EXCLUDE_ALWAYS = {\"Booking ID\", \"Customer ID\", \"pick_address\", \"drop_address\"}\n",
    "\n",
    "def infer_feature_lists(df: pd.DataFrame, target_col: str) -> Tuple[List[str], List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Build three feature lists:\n",
    "      - numeric_features: *_scaled, *_log_scaled, numeric *_fill, and selected raw numeric whitelist\n",
    "      - categorical_features: non-numeric *_fill + 'Vehicle Type'\n",
    "      - missing_flags: *_missing_flag\n",
    "    \"\"\"\n",
    "    cols = [c for c in df.columns if c != target_col and c not in EXCLUDE_ALWAYS]\n",
    "\n",
    "    # Naming-based groups\n",
    "    scaled = [c for c in cols if c.endswith(\"_scaled\") or c.endswith(\"_log_scaled\")]\n",
    "    fill   = [c for c in cols if c.endswith(\"_fill\")]  # may be numeric or categorical\n",
    "    flags  = [c for c in cols if c.endswith(\"_missing_flag\")]\n",
    "    cat_seed = [c for c in cols if c == \"Vehicle Type\"]\n",
    "\n",
    "    # Split *_fill by dtype to avoid one-hotting numeric fills\n",
    "    numeric_fill = [c for c in fill if pd.api.types.is_numeric_dtype(df[c])]\n",
    "    categorical_fill = [c for c in fill if not pd.api.types.is_numeric_dtype(df[c])]\n",
    "\n",
    "    # Add raw numeric whitelist if present\n",
    "    numeric_raw = [c for c in NUMERIC_RAW_WHITELIST if c in df.columns]\n",
    "\n",
    "    # Combine\n",
    "    numeric_features     = scaled + numeric_fill + numeric_raw\n",
    "    categorical_features = cat_seed + categorical_fill\n",
    "    missing_flags        = flags\n",
    "\n",
    "    # De-duplicate while preserving order\n",
    "    def uniq(seq):\n",
    "        seen = set(); out = []\n",
    "        for x in seq:\n",
    "            if x not in seen:\n",
    "                out.append(x); seen.add(x)\n",
    "        return out\n",
    "\n",
    "    numeric_features     = uniq(numeric_features)\n",
    "    categorical_features = uniq(categorical_features)\n",
    "    missing_flags        = uniq(missing_flags)\n",
    "\n",
    "    print(f\"#numeric={len(numeric_features)}  #categorical={len(categorical_features)}  #flags={len(missing_flags)}\")\n",
    "    print(\"Numeric (sample):\", numeric_features[:8])\n",
    "    print(\"Categorical (sample):\", categorical_features[:8])\n",
    "    print(\"Flags (sample):\", missing_flags[:8])\n",
    "\n",
    "    return numeric_features, categorical_features, missing_flags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "09d37779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Cell 3) Build preprocessor\n",
    "# -----------------------------\n",
    "def build_preprocessor(\n",
    "    numeric_scaled: List[str],\n",
    "    categorical_fill: List[str],\n",
    "    missing_flags: List[str]\n",
    ") -> ColumnTransformer:\n",
    "    \"\"\"\n",
    "    One-hot encode categorical; passthrough numeric+flags (already scaled / binary).\n",
    "    \"\"\"\n",
    "    num_and_flags = numeric_scaled + missing_flags\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_fill),\n",
    "            (\"num\", \"passthrough\", num_and_flags),\n",
    "        ],\n",
    "        remainder=\"drop\",\n",
    "    )\n",
    "    return preprocessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8aa15080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Cell 4) Model registry\n",
    "# -----------------------------\n",
    "def get_models(random_state: int = 42) -> Dict[str, object]:\n",
    "    \"\"\"\n",
    "    Baselines for logistic regression, decision tree, and ensembles.\n",
    "    \"\"\"\n",
    "    models = {\n",
    "        \"logreg_l2\": LogisticRegression(\n",
    "            max_iter=1000,\n",
    "            class_weight=\"balanced\",\n",
    "            random_state=random_state\n",
    "        ),\n",
    "        \"dtree\": DecisionTreeClassifier(\n",
    "            max_depth=None,\n",
    "            min_samples_split=5,\n",
    "            class_weight=\"balanced\",\n",
    "            random_state=random_state\n",
    "        ),\n",
    "        \"rf_300\": RandomForestClassifier(\n",
    "            n_estimators=300,\n",
    "            max_depth=None,\n",
    "            n_jobs=-1,\n",
    "            class_weight=\"balanced\",\n",
    "            random_state=random_state\n",
    "        ),\n",
    "        \"gbdt\": GradientBoostingClassifier(\n",
    "            random_state=random_state\n",
    "        ),\n",
    "    }\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8a1cfe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Cell 5) Exact-label mapping & safer CV\n",
    "# -----------------------------\n",
    "from typing import Optional, Iterable\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def map_status_to_binary_exact_labels(s: str, positive_label_set: Iterable[str]) -> int:\n",
    "    \"\"\"\n",
    "    Map Booking Status to binary using an explicit label set.\n",
    "    Returns 1 if the normalized label is in positive_label_set, else 0.\n",
    "    \"\"\"\n",
    "    if pd.isna(s):\n",
    "        return 0\n",
    "    s_norm = str(s).strip()\n",
    "    return int(s_norm in set(positive_label_set))\n",
    "\n",
    "def safe_stratified_cv(y_bin: pd.Series, n_splits: int = 5, random_state: int = 42):\n",
    "    \"\"\"\n",
    "    Yield StratifiedKFold splits ensuring at least 2 classes per fold.\n",
    "    Reduce n_splits if the minority class is too small; skip degenerate folds.\n",
    "    \"\"\"\n",
    "    vc = y_bin.value_counts()\n",
    "    if vc.nunique() == 1:\n",
    "        raise ValueError(\n",
    "            \"Only one class present overall after mapping. Adjust your positive_label_set or labels.\"\n",
    "        )\n",
    "    minority = vc.min()\n",
    "    n_splits = min(n_splits, minority)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    for fold_id, (tr_idx, va_idx) in enumerate(skf.split(np.zeros(len(y_bin)), y_bin), 1):\n",
    "        y_tr, y_va = y_bin.iloc[tr_idx], y_bin.iloc[va_idx]\n",
    "        if y_tr.nunique() < 2 or y_va.nunique() < 2:\n",
    "            print(f\"⚠️ Skipping fold {fold_id}: single class in train/valid.\")\n",
    "            continue\n",
    "        yield fold_id, tr_idx, va_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9de5b977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Cell 6) Evaluate models with CV (exact label set)\n",
    "# -----------------------------\n",
    "def evaluate_models_cv(\n",
    "    df: pd.DataFrame,\n",
    "    target_col: str,\n",
    "    positive_label_set: Iterable[str],\n",
    "    n_splits: int = 5,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build preprocessor, train multiple models with StratifiedKFold CV,\n",
    "    and return a tidy metrics dataframe:\n",
    "      ['run_id','timestamp','model_name','fold','metric','value','params']\n",
    "    \"\"\"\n",
    "    # 1) Normalize target text and map to binary via exact label set\n",
    "    y_text = df[target_col].astype(str).str.strip()\n",
    "    y_bin = y_text.apply(lambda s: map_status_to_binary_exact_labels(s, positive_label_set)).astype(int)\n",
    "    print(\"Label distribution:\", y_bin.value_counts().to_dict())\n",
    "    if y_bin.value_counts().min() < 2:\n",
    "        raise ValueError(\"Not enough minority samples. Adjust positive_label_set or filter data.\")\n",
    "\n",
    "    # 2) Infer features & build X\n",
    "    numeric_scaled, categorical_fill, missing_flags = infer_feature_lists(df, target_col)\n",
    "    X = df[numeric_scaled + categorical_fill + missing_flags].copy()\n",
    "\n",
    "    # 3) Preprocessor & models\n",
    "    pre = build_preprocessor(numeric_scaled, categorical_fill, missing_flags)\n",
    "    models = get_models()\n",
    "\n",
    "    # 4) CV loop\n",
    "    rows = []\n",
    "    run_id = str(uuid.uuid4())\n",
    "    ts = int(time.time())\n",
    "\n",
    "    for model_name, base_model in models.items():\n",
    "        pipe = Pipeline(steps=[(\"preprocess\", pre), (\"model\", base_model)])\n",
    "        for fold_id, tr_idx, va_idx in safe_stratified_cv(y_bin, n_splits=n_splits):\n",
    "            X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "            y_tr, y_va = y_bin.iloc[tr_idx], y_bin.iloc[va_idx]\n",
    "\n",
    "            pipe.fit(X_tr, y_tr)\n",
    "            y_pred = pipe.predict(X_va)\n",
    "\n",
    "            # probabilities for ROC-AUC if supported\n",
    "            try:\n",
    "                y_proba = pipe.predict_proba(X_va)[:, 1]\n",
    "                roc = roc_auc_score(y_va, y_proba)\n",
    "            except Exception:\n",
    "                roc = np.nan\n",
    "\n",
    "            metrics = {\n",
    "                \"f1\": f1_score(y_va, y_pred, zero_division=0),\n",
    "                \"precision\": precision_score(y_va, y_pred, zero_division=0),\n",
    "                \"recall\": recall_score(y_va, y_pred, zero_division=0),\n",
    "                \"accuracy\": accuracy_score(y_va, y_pred),\n",
    "                \"roc_auc\": roc,\n",
    "            }\n",
    "\n",
    "            for m, v in metrics.items():\n",
    "                rows.append({\n",
    "                    \"run_id\": run_id,\n",
    "                    \"timestamp\": ts,\n",
    "                    \"model_name\": model_name,\n",
    "                    \"fold\": fold_id,\n",
    "                    \"metric\": m,\n",
    "                    \"value\": float(v),\n",
    "                    \"params\": str(base_model.get_params())\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "09aa6f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146614, 68)\n",
      "Index(['Date', 'Time', 'booking_datetime', 'booking_hour', 'Booking ID',\n",
      "       'Booking Status', 'Customer ID', 'Vehicle Type', 'Pickup Location',\n",
      "       'Drop Location'],\n",
      "      dtype='object')\n",
      "Unknown labels (not in POSITIVE or NEGATIVE sets): []\n",
      "Label distribution: {0: 90896, 1: 55718}\n",
      "#numeric_scaled=20, #categorical_fill=9, #missing_flags=3\n",
      "Saved metrics to artifacts/metrics/metrics.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dtree</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gbdt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logreg_l2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rf_300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_name  mean  std\n",
       "0      dtree   1.0  0.0\n",
       "1       gbdt   1.0  0.0\n",
       "2  logreg_l2   1.0  0.0\n",
       "3     rf_300   1.0  0.0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Cell 7) Run: load data, set positive labels, evaluate, save, leaderboard\n",
    "# -----------------------------\n",
    "# 7.1 Load cleaned CSV from teammate\n",
    "csv_path = \"ncr_ride_bookings_with_weather_filled_scaled_short.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# (optional) quick peek\n",
    "print(df.shape)\n",
    "print(df.columns[:10])\n",
    "\n",
    "# 7.2 Choose target & define exact positive label set based on your dataset\n",
    "target_col = \"Booking Status\"\n",
    "\n",
    "# From your screenshot / dataset (adjust if you find more):\n",
    "# { \"Cancelled by Customer\", \"Cancelled by Driver\", \"Completed\", \"Incomplete\", \"No Driver Found\" }\n",
    "POSITIVE_LABELS = {\n",
    "    \"Cancelled by Customer\",\n",
    "    \"Cancelled by Driver\",\n",
    "    \"Incomplete\",\n",
    "    \"No Driver Found\"\n",
    "}\n",
    "NEGATIVE_LABELS = {\"Completed\"}  # optional for sanity check\n",
    "\n",
    "# Sanity: list unknown labels not covered by the sets\n",
    "df[target_col] = df[target_col].astype(str).str.strip()\n",
    "known = POSITIVE_LABELS | NEGATIVE_LABELS\n",
    "unknown = sorted(set(df[target_col].unique()) - known)\n",
    "print(\"Unknown labels (not in POSITIVE or NEGATIVE sets):\", unknown)\n",
    "\n",
    "# 7.3 Evaluate with CV using the exact label set\n",
    "metrics_df = evaluate_models_cv(\n",
    "    df=df,\n",
    "    target_col=target_col,\n",
    "    positive_label_set=POSITIVE_LABELS,\n",
    "    n_splits=5\n",
    ")\n",
    "\n",
    "# 7.4 Save metrics CSV for visualization teammate\n",
    "from pathlib import Path\n",
    "Path(\"artifacts/metrics\").mkdir(parents=True, exist_ok=True)\n",
    "out_csv = \"artifacts/metrics/metrics.csv\"\n",
    "metrics_df.to_csv(out_csv, index=False)\n",
    "print(f\"Saved metrics to {out_csv}\")\n",
    "\n",
    "# 7.5 Quick leaderboard by F1\n",
    "leaderboard = (\n",
    "    metrics_df[metrics_df[\"metric\"] == \"f1\"]\n",
    "    .groupby(\"model_name\")[\"value\"].agg([\"mean\", \"std\"])\n",
    "    .sort_values(\"mean\", ascending=False)\n",
    "    .reset_index()\n",
    ")\n",
    "leaderboard\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f73d7848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>model_name</th>\n",
       "      <th>fold</th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7239cfc4-e81d-4af7-886f-0afe169f23d5</td>\n",
       "      <td>1758220009</td>\n",
       "      <td>logreg_l2</td>\n",
       "      <td>1</td>\n",
       "      <td>f1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 1.0, 'class_weight': 'balanced', 'dual':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7239cfc4-e81d-4af7-886f-0afe169f23d5</td>\n",
       "      <td>1758220009</td>\n",
       "      <td>logreg_l2</td>\n",
       "      <td>1</td>\n",
       "      <td>precision</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 1.0, 'class_weight': 'balanced', 'dual':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7239cfc4-e81d-4af7-886f-0afe169f23d5</td>\n",
       "      <td>1758220009</td>\n",
       "      <td>logreg_l2</td>\n",
       "      <td>1</td>\n",
       "      <td>recall</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 1.0, 'class_weight': 'balanced', 'dual':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7239cfc4-e81d-4af7-886f-0afe169f23d5</td>\n",
       "      <td>1758220009</td>\n",
       "      <td>logreg_l2</td>\n",
       "      <td>1</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 1.0, 'class_weight': 'balanced', 'dual':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7239cfc4-e81d-4af7-886f-0afe169f23d5</td>\n",
       "      <td>1758220009</td>\n",
       "      <td>logreg_l2</td>\n",
       "      <td>1</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 1.0, 'class_weight': 'balanced', 'dual':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7239cfc4-e81d-4af7-886f-0afe169f23d5</td>\n",
       "      <td>1758220009</td>\n",
       "      <td>logreg_l2</td>\n",
       "      <td>2</td>\n",
       "      <td>f1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 1.0, 'class_weight': 'balanced', 'dual':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7239cfc4-e81d-4af7-886f-0afe169f23d5</td>\n",
       "      <td>1758220009</td>\n",
       "      <td>logreg_l2</td>\n",
       "      <td>2</td>\n",
       "      <td>precision</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 1.0, 'class_weight': 'balanced', 'dual':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7239cfc4-e81d-4af7-886f-0afe169f23d5</td>\n",
       "      <td>1758220009</td>\n",
       "      <td>logreg_l2</td>\n",
       "      <td>2</td>\n",
       "      <td>recall</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 1.0, 'class_weight': 'balanced', 'dual':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7239cfc4-e81d-4af7-886f-0afe169f23d5</td>\n",
       "      <td>1758220009</td>\n",
       "      <td>logreg_l2</td>\n",
       "      <td>2</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 1.0, 'class_weight': 'balanced', 'dual':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7239cfc4-e81d-4af7-886f-0afe169f23d5</td>\n",
       "      <td>1758220009</td>\n",
       "      <td>logreg_l2</td>\n",
       "      <td>2</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 1.0, 'class_weight': 'balanced', 'dual':...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 run_id   timestamp model_name  fold  \\\n",
       "0  7239cfc4-e81d-4af7-886f-0afe169f23d5  1758220009  logreg_l2     1   \n",
       "1  7239cfc4-e81d-4af7-886f-0afe169f23d5  1758220009  logreg_l2     1   \n",
       "2  7239cfc4-e81d-4af7-886f-0afe169f23d5  1758220009  logreg_l2     1   \n",
       "3  7239cfc4-e81d-4af7-886f-0afe169f23d5  1758220009  logreg_l2     1   \n",
       "4  7239cfc4-e81d-4af7-886f-0afe169f23d5  1758220009  logreg_l2     1   \n",
       "5  7239cfc4-e81d-4af7-886f-0afe169f23d5  1758220009  logreg_l2     2   \n",
       "6  7239cfc4-e81d-4af7-886f-0afe169f23d5  1758220009  logreg_l2     2   \n",
       "7  7239cfc4-e81d-4af7-886f-0afe169f23d5  1758220009  logreg_l2     2   \n",
       "8  7239cfc4-e81d-4af7-886f-0afe169f23d5  1758220009  logreg_l2     2   \n",
       "9  7239cfc4-e81d-4af7-886f-0afe169f23d5  1758220009  logreg_l2     2   \n",
       "\n",
       "      metric  value                                             params  \n",
       "0         f1    1.0  {'C': 1.0, 'class_weight': 'balanced', 'dual':...  \n",
       "1  precision    1.0  {'C': 1.0, 'class_weight': 'balanced', 'dual':...  \n",
       "2     recall    1.0  {'C': 1.0, 'class_weight': 'balanced', 'dual':...  \n",
       "3   accuracy    1.0  {'C': 1.0, 'class_weight': 'balanced', 'dual':...  \n",
       "4    roc_auc    1.0  {'C': 1.0, 'class_weight': 'balanced', 'dual':...  \n",
       "5         f1    1.0  {'C': 1.0, 'class_weight': 'balanced', 'dual':...  \n",
       "6  precision    1.0  {'C': 1.0, 'class_weight': 'balanced', 'dual':...  \n",
       "7     recall    1.0  {'C': 1.0, 'class_weight': 'balanced', 'dual':...  \n",
       "8   accuracy    1.0  {'C': 1.0, 'class_weight': 'balanced', 'dual':...  \n",
       "9    roc_auc    1.0  {'C': 1.0, 'class_weight': 'balanced', 'dual':...  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# (Optional) Cell 8) Peek metrics\n",
    "# -----------------------------\n",
    "pd.read_csv(\"artifacts/metrics/metrics.csv\").head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad5e9ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
